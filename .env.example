# LLM Provider Configuration
# Choose ONE of the following (in priority order):

# Google Gemini Flash (free and fast, RECOMMENDED)
GEMINI_API_KEY=your_gemini_api_key_here

# Groq Inference (free, also good)
# GROQ_API_URL=https://api.groq.com/openai/v1/chat/completions
# GROQ_API_KEY=your_groq_api_key_here

# OpenAI (paid)
# OPENAI_API_KEY=sk_your_openai_key_here

# Database (optional, default is local JSON at data/db.json)
# DATABASE_URL=postgresql://user:password@localhost:5432/justwrite

# Supabase Authentication (required for multi-user)
# Get these from https://supabase.com (Settings > API)
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key_here

# IMPORTANT: Service Role Key (required for server-side operations like delete)
# This bypasses Row Level Security - NEVER expose to client/browser
# Get from Supabase Dashboard: Settings > API > service_role (secret)
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key_here

# Note: Copy this file to .env.local and fill in actual values
# NEVER commit .env.local to version control

